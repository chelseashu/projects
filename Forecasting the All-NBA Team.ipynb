{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting the All-NBA Team \n",
    "## by Chelsea Shu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All-NBA team from 1988-1989 to 2016-2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has a list of players who have made the All-NBA team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'All.NBA.1984-2018.csv' does not exist: b'All.NBA.1984-2018.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-808bf2705b3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_nba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'All.NBA.1984-2018.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mall_nba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mall_nba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_nba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mall_nba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_nba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mall_nba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'All.NBA.1984-2018.csv' does not exist: b'All.NBA.1984-2018.csv'"
     ]
    }
   ],
   "source": [
    "all_nba = pd.read_csv('All.NBA.1984-2018.csv')\n",
    "print (all_nba.shape)\n",
    "all_nba.columns = all_nba.iloc[0]\n",
    "all_nba = all_nba.drop(0)\n",
    "all_nba.head()\n",
    "all_nba.reset_index(0)\n",
    "all_nba.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the All-NBA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = all_nba['Season'].str[0:2].astype(str) + all_nba['Season'].str[-2:].astype(str)\n",
    "\n",
    "for i,num in enumerate(string):\n",
    "    if num == '1900':\n",
    "        string[i+1] = '2000'\n",
    "\n",
    "all_nba['Season'] = string.astype(int)\n",
    "all_nba = all_nba.drop(all_nba[all_nba[\"Season\"] < 1989].index)\n",
    "all_nba.reset_index(inplace = True)\n",
    "all_nba.Season = all_nba.Season.astype(int).astype(str)\n",
    "all_nba.Age = all_nba.Age.astype(int).astype(str)\n",
    "all_nba.head()\n",
    "all_nba.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon initial glance at the data for all seasons, which is shown below, I notice the dates are listed as a single year. To be consistent, I change the dates in the \"all_nba\" dataset to be single years. I assign the years to be the second year in the date range.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for null values\n",
    "all_nba.isnull().sum()\n",
    "all_nba.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Player stats data each season from 1988-1989 to 2016-2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that my dataset is from 1950-2017, I select player statistics from 1989-2017. The reason for this is because the 1988-1989 season is the first season where 15 players are selected to the All-NBA team, rather than 10 players. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_stats = pd.read_csv(\"players.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_stats = pd.read_csv(\"players.csv\")\n",
    "season_stats = season_stats.drop(\"Unnamed: 0\", axis =1)\n",
    "indexnames = season_stats[season_stats['Year'] <= 1988.0].index\n",
    "season_stats = season_stats.drop(indexnames)\n",
    "season_stats = season_stats.dropna(how = 'all')\n",
    "season_stats.reset_index(inplace = True)\n",
    "season_stats = season_stats.drop(columns = 'index')\n",
    "season_stats.Year = season_stats.Year.astype(int).astype(str)\n",
    "season_stats.Age = season_stats.Age.astype(int).astype(str)\n",
    "season_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I check for null values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for null values\n",
    "season_stats.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems there are two columns that are completely filled with null values, so I remove those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove blank columns\n",
    "season_stats.drop(['blanl', 'blank2'], axis = 1, inplace = True)\n",
    "season_stats.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I notice that PER and USG% (which are both important basketball statistics) each have 5 null values, so I explore further to see if there is a relationship between both of these columns have null values.  It actually turns out that there are null values in USG% and PER for players that did not play any minutes throughout the season. Since they did not play, I can remove them from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check USAGE and PER because these are important, explore why they are null\n",
    "\n",
    "null_columns = season_stats.columns[season_stats.isnull().any()]\n",
    "null_PER = season_stats[season_stats[\"PER\"].isnull()][null_columns]\n",
    "null_USG = season_stats[season_stats[\"PER\"].isnull()][null_columns]\n",
    "null_USG.equals(null_PER)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore why PER is Nan and USG is Nan\n",
    "season_stats.loc[season_stats['PER'].isnull()]\n",
    "\n",
    "season_stats = season_stats.drop(season_stats.loc[season_stats['PER'].isnull()].index)\n",
    "season_stats.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some players that have only played a few games or few minutes and they have been able to accumulate stats from their time played in blowout games. This kind of data does not help to predict who gets selected to the All-NBA team, so I will remove any players that played less than 15% of the 82 games in the season and less than 10% of the total minutes in a season. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_stats = season_stats[season_stats[\"G\"] >= .15*82]\n",
    "season_stats = season_stats[season_stats[\"MP\"] > (.1 * 48 * 82)]\n",
    "season_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for null values again\n",
    "season_stats.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to explore more why the 3 point percentage is null, so I take a look at the \"3P\" and \"3PA\" variables where \"3P%\" is null. Once I print out the values, I can see that both \"3P\" and \"3PA\" are zeros, meaning that \"3P%\" is zero, but it errors and puts \"NaN\" because of the division by 0. So in order to fix this, since we know the 3-pointer percentage is 0, we can replace the NaN values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_3ppercent = season_stats[season_stats[\"3P%\"].isnull()]\n",
    "\n",
    "print (\"3PA values where 3P% is null\",null_3ppercent['3PA'])\n",
    "print (\"3P values where 3P% is null\",null_3ppercent['3P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_3ppercent = season_stats[\"3P%\"]\n",
    "null_3ppercent.fillna('0', inplace = True)\n",
    "#double check the null values\n",
    "season_stats.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to add a column into the season stats data for whether a player is on the all-NBA team in a given season. To do this I create a unique identifier based on the player's basic information(i.e. name, year, team, and age). I use four columns instead of just using the name to uniquely identify the player because the player's name could show up many times for different seasons of being on the All-NBA team. Then I give players who made the All-NBA team in a given year (this information is from my all_nba table) a 1 and players who did not make the team a 0.  I then output how many all-NBA players in each year to double check that there are 15 in each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##creating unique identifier for each unique row\n",
    "unique = list(season_stats['Year'].astype(str)+season_stats['Player'].str[0:5].astype(str) + season_stats['Tm'].astype(str) + season_stats['Age'].astype(str))\n",
    "unique_all_nba = list(all_nba['Season'].astype(str)+all_nba['Player'].str[0:5].astype(str) + all_nba['Tm'].astype(str) + all_nba['Age'].astype(str))\n",
    "\n",
    "season_stats[\"ID\"] = unique\n",
    "all_nba[\"ID\"]= unique_all_nba\n",
    "\n",
    "nba_list = []\n",
    "for i in unique:\n",
    "    if i in unique_all_nba:\n",
    "        nba_list.append(1)\n",
    "    else:\n",
    "        nba_list.append(0)\n",
    "        \n",
    "season_stats[\"all_nba\"] = nba_list\n",
    "\n",
    "grouped = season_stats.groupby([\"Year\"]).all_nba.value_counts()\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_stats[season_stats[\"Year\"] == \"1990\"][season_stats[\"Player\"] == \"Chris Welp\"]\n",
    "season_stats.loc[862, 'all_nba'] =0\n",
    "season_stats.loc[862]\n",
    "\n",
    "season_stats[season_stats[\"Year\"] == \"2013\"][season_stats[\"Player\"] == \"James Harden\"]\n",
    "season_stats.loc[12754, 'all_nba'] = 0\n",
    "\n",
    "grouped = season_stats.groupby([\"Year\"]).all_nba.value_counts()\n",
    "grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##adding a column for if a player made the all-nba team the previous year\n",
    "season_stats[\"last_year\"] = 0\n",
    "\n",
    "for player in season_stats[\"Player\"]:\n",
    "    b = season_stats[season_stats[\"Player\"]== player][season_stats[\"all_nba\"] == 1][\"Year\"]\n",
    "    a = season_stats[season_stats[\"Player\"]== player][\"Year\"]\n",
    "\n",
    "    for i in a.index:\n",
    "        if (str(int(a[i])-1)) in b.values:\n",
    "            season_stats.loc[i, \"last_year\"] = 1\n",
    "        else:\n",
    "            season_stats.loc[i, \"last_year\"] = 0\n",
    "\n",
    "season_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hard coding that these ten players made it the year before because we do not have data in our dataset about 1988\n",
    "players_1988 = [\"Charles Barkley*\", \"Larry Bird*\",\"Hakeem Olajuwon*\", \"Michael Jordan*\",  \"Magic Johnson*\", \"Karl Malone*\",\n",
    "               \"Dominique Wilkins*\",\"Patrick Ewing*\", \"John Stockton*\", \"Clyde Drexler*\"]\n",
    "for p in players_1988:\n",
    "    row = season_stats[season_stats[\"Player\"]== p][season_stats[\"Year\"] == \"1989\"].index\n",
    "    for j in row:\n",
    "        season_stats.loc[j, 'last_year'] = 1\n",
    "season_stats.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making labels_list with how many all_nbas they get in lifetime\n",
    "new = season_stats.sort_values(by=['Player', \"Age\"])\n",
    "labels_list = []\n",
    "data_list = []\n",
    "unique_players = new[\"Player\"].drop_duplicates()\n",
    "new_df = pd.DataFrame()\n",
    "for i in unique_players:\n",
    "    labels_list.append(len(new[new[\"Player\"] == i][new[\"all_nba\"] == 1]))\n",
    "    new_df = new_df.append(new[new['Player'] == i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.drop(new_df[new_df['Tm'] == 'TOT'].index, inplace = True) \n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have done a lot of data cleaning, so here is my final dataset that I will be using. It has statistics for every player from 1989 to 2017 and includes a column for whether they made the All-NBA team  in a particular year or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_stats = new_df\n",
    "season_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age and Player Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the nature of basketball and aging, I suspect that there might be a relationship between age and how efficient a player is. I suspect that while players are young, their performance will get better and better, but once they've reached their peak age, their performance will start to decrease. I will explore that below. To measure, I will plot the relationshp between age and PER, which is a measure of the player's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking age and PER\n",
    "x = []\n",
    "y = []\n",
    "for i in sorted(season_stats.Age.unique()):\n",
    "    year = season_stats[season_stats.Age == i]\n",
    "    per = np.mean(year['PER'])\n",
    "    \n",
    "    x.append(i)\n",
    "    y.append(per)\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"PER\")\n",
    "plt.title(\"Relationship between a Player's Age and PER\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from this graph, player performance increases until a peak age of 26, and then it decreases steadily after that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Payer Efficiency and Other Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to check what other features are correlated with high performance. I suspect that points, assists, rebounds, and win shares will be highly correlated with PER because the more of these metrics a player has, the more likely they perform well. Let's explore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,ax = plt.subplots(2, 2, figsize = (15,15))   #subplots\n",
    "ax = ax.flatten()\n",
    "        \n",
    "ax[0].scatter(season_stats.PTS, season_stats.PER)\n",
    "ax[0].set_title(\"Points vs PER\")\n",
    "ax[0].set_xlabel(\"Points\")\n",
    "ax[0].set_ylabel(\"PER\")\n",
    "\n",
    "ax[1].scatter(season_stats.TRB, season_stats.PER)\n",
    "ax[1].set_title(\"Rebounds vs PER\")\n",
    "ax[1].set_xlabel(\"Rebounds\")\n",
    "ax[1].set_ylabel(\"PER\")\n",
    "\n",
    "ax[2].scatter(season_stats.AST, season_stats.PER)\n",
    "ax[2].set_title(\"Assists vs PER\")\n",
    "ax[2].set_xlabel(\"Assists\")\n",
    "ax[2].set_ylabel(\"PER\")\n",
    "\n",
    "ax[3].scatter(season_stats.WS, season_stats.PER)\n",
    "ax[3].set_title(\"Win Shares vs PER\")\n",
    "ax[3].set_xlabel(\"Win Shares\")\n",
    "ax[3].set_ylabel(\"PER\")\n",
    "\n",
    "plt.subplots_adjust(left=.5, bottom=.5, right=1, top=1, wspace=.75, hspace=.75)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My graphs confirm my suspicions. Each of these variables has a positive correlation with the player's efficiency rating. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have the most accurate model, I want to pick features that contribute most to whether someone makes the All-NBA team or not.  Looking at the columns, I notice that there are columns that are calculated from other columns (i.e. Free throw percentage (FT%) is equal to the column FT (free throws) divided by FTA (free throw attempts)). Having all three columns there seems repetitive so I will take certain columns out and leave just the percentage columns, since they capture the amount of attempts as well as successful attempts. I also remove redundant columns like WS (win shares) and WS/48.  I aso notice that some columns serve purposes for only certain player positions (i.e. DRB (defensive rebounds) would not be a strong statistic for offensive player positions), so I will drop these columns and keep the column that captures the total (i.e. Total Rebounds). Removing these columns will allow my model to be the best predictive model. \n",
    "\n",
    "Because I want to determine the All-NBA team based on players' abilities, I will remove two columns, Value Over Replacement Player (VORP) and Box Plus/Minus (BPM). The reason for removing these columns is because these statistics are not statistics that directly describe the player's direct statistics from playing games in the NBA. Rather, they are metrics that describe a player's value. This can introduce problems because this metric can be calculated in a way that does not objectively describe the player. \n",
    "\n",
    "Additionally, I also use certain features such as Age and whether a player made the All-NBA team the previous year. I suspect that players that made the team the year before are more likely to make the team again, so I want to explore if this is an important feature in predicting who makes the All-NBA team..\n",
    "\n",
    "I then explore the top ten columns that contribute the most to who make the All-NBA team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExtraTreesClassifier()\n",
    "columns = ['Age', 'G', 'GS', 'MP', 'PER', 'TS%',\n",
    "       '3PAr', 'FTr', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%',\n",
    "       'USG%',  'WS',  \n",
    "       'FG%',  '3P%',  '2P%', 'eFG%',\n",
    "       'FT%',  'TRB', 'AST', 'STL', 'BLK', 'TOV',\n",
    "       'PF', 'PTS', 'last_year']\n",
    "model.fit(season_stats[columns],season_stats['all_nba'])\n",
    "#plot graph of feature importances\n",
    "feat_importances = pd.Series(model.feature_importances_, index=season_stats[columns].columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()\n",
    "print (feat_importances.nlargest(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from our bar plot, making the All-NBA team the previous year is a very important feature in determining who makes the team. Other statistics that contribute to predicting the All-NBA team are player efficiency (PER), points, win shares, rebounds, etc. \n",
    "\n",
    "I will use these ten columns in my model. It is important to note that while other features such as age may seem like they correlate with whether a player makes the All-NBA team (because as a player gets older, they play worse), the differences in how players perform when they are older are reflected in their player statistics (i.e. points, rebounds, etc). For that reason, age does not contribute much to predicting the All-NBA team, but rather other statistics do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the nature of basketball, player statistics are season-dependent. For this reason, I decide to split my test and train data using backtesting. I train my model on two seasons and predict for the following season for every season from 1989 until 2017. For example, I might train my data on the 2007 and 2008 seasons, and I will test on the 2009 season. \n",
    "\n",
    "Within the All-NBA team, there are three tiers of teams, each with 1 guard, 2 forwards, and 2 centers, meaning that there are 3 guards, 6 forwards, and 6 centers that are on the All-NBA team. After my model predicts probabilities that each player will make the team, I choose the 3 guards, 6 forwards, and 6 centers with the highest probabilities of making the team. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ['GS', 'MP', 'PER', 'USG%',  'WS', 'TRB', 'AST',  'TOV', 'PTS', 'last_year']\n",
    "\n",
    "for i in sorted(season_stats.Year.unique())[0:-2]:\n",
    "    season_train_data = season_stats[season_stats.Year == i]\n",
    "    season_train_data = season_train_data.append(season_stats[season_stats.Year ==  str(int(i)+1)])\n",
    "    train_data = season_train_data[feature]\n",
    "    \n",
    "    season_test_data = season_stats[season_stats.Year == str(int(i)+2)]\n",
    "    season_test_data = season_test_data.replace({'PG': 'G','SG':'G','PF':'F', \"SF\": 'F', 'PF-C': 'F'})\n",
    "    season_test_data = season_test_data.sort_values(by=['Pos'])\n",
    "    test_data = season_test_data[feature]\n",
    "\n",
    "    test_labels = season_test_data['all_nba']\n",
    "    train_labels = season_stats[season_stats.Year == i]['all_nba']\n",
    "    train_labels = train_labels.append(season_stats[season_stats.Year == str(int(i)+1)]['all_nba'])\n",
    "  \n",
    "    f1 = []\n",
    "    f1_1 = []\n",
    "    f1_0 = []\n",
    "    RF = RandomForestClassifier(n_estimators =100, max_depth = 2, random_state = 0)\n",
    "    RF.fit(train_data, train_labels)\n",
    "\n",
    "    predicted_prob=RF.predict_proba(test_data)\n",
    "    season_test_data['predicted_prob'] = predicted_prob[:,1]\n",
    "\n",
    "    #predicted labels based on position restraints\n",
    "    team = []\n",
    "    for i in season_test_data.Pos.unique():\n",
    "        if i == 'C':\n",
    "            pos = season_test_data[season_test_data['Pos']  == i]\n",
    "            largest=pos.nlargest(3, ['predicted_prob'])['Player'].tolist()\n",
    "\n",
    "        else:\n",
    "            pos = season_test_data[season_test_data['Pos']  == i]\n",
    "            largest  = pos.nlargest(6, ['predicted_prob'])[\"Player\"].tolist()\n",
    "        for i in range(len(largest)):\n",
    "            team.append(largest[i])\n",
    "    \n",
    "    test_predicted_labels = []\n",
    "    for p in season_test_data.Player:\n",
    "\n",
    "        if p in team:\n",
    "            test_predicted_labels.append(1)\n",
    "        else:\n",
    "            test_predicted_labels.append(0)\n",
    "    f1.append(f1_score(season_test_data['all_nba'], test_predicted_labels,  average = 'weighted'))\n",
    "    f1_1.append(f1_score(season_test_data['all_nba'], test_predicted_labels, pos_label =1, average = 'binary'))\n",
    "    f1_0.append(f1_score(season_test_data['all_nba'], test_predicted_labels, pos_label = 0, average = 'binary'))\n",
    "\n",
    "print (\"Weighted accuracy: \" + str(np.mean(f1)))\n",
    "print (\"Accuracy of classifing who did NOT make the All-NBA team: \" + str(np.mean(f1_0)))  \n",
    "print (\"Accuracy of classifying who did make the All-NBA team: \" + str(np.mean(f1_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, when the model predicts who does not make the team, it does so with 99% accuracy. However, when it predicts who will make the All-NBA team, it predicts with 80% accuracy. The reason for this is because there are only 15 players each year that get picked to the All-NBA team. Therefore, if the model misclassifies even just one or two players, the accuracy drops immensely. \n",
    "\n",
    "Overall, the model does a great job. It classifies whether players will make the All-NBA team or not correctly 98.4% of the time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
